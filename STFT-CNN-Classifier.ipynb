{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labeled data\n",
    "good_examples = pd.read_csv('./InDaS Labeled/good_period_2024_01_03.csv')\n",
    "good_examples\n",
    "\n",
    "bad_examples = pd.read_csv('./InDaS Labeled/bad_period_2024_01_06.csv')\n",
    "bad_examples\n",
    "\n",
    "all_good_segments = []\n",
    "all_bad_segments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Good Cutting Data: 4552\n",
      "Shape of Segment 1: (1668, 11)\n",
      "Shape of Torque Data: (1668,)\n"
     ]
    }
   ],
   "source": [
    "# Apply the indicator function to create a new column\n",
    "good_examples['indicator'] = good_examples.apply(lambda x: 1 if x['rel_time'] == 0 else 0, axis=1)\n",
    "\n",
    "start_indices_good = good_examples.index[good_examples['indicator'] == 1].tolist()\n",
    "\n",
    "# Add the end of the DataFrame as the last index\n",
    "start_indices_good.append(len(good_examples))\n",
    "\n",
    "\n",
    "# Loop through each segment and plot, limiting the number of rotations\n",
    "for i in range(len(start_indices_good)-1):\n",
    "    good_segment = good_examples.iloc[start_indices_good[i]:start_indices_good[i + 1]]\n",
    "    all_good_segments.append(good_segment)\n",
    "\n",
    "print(\"Total Good Cutting Data:\", len(all_good_segments))\n",
    "print(\"Shape of Segment 1:\", all_good_segments[0].shape)\n",
    "print(\"Shape of Torque Data:\", all_good_segments[0]['Torque'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Bad Cutting Data: 1937\n",
      "Shape of Segment 1: (1668, 11)\n",
      "Shape of Torque Data: (1668,)\n"
     ]
    }
   ],
   "source": [
    "# Apply the indicator function to create a new column\n",
    "bad_examples['indicator'] = bad_examples.apply(lambda x: 1 if x['rel_time'] == 0 else 0, axis=1)\n",
    "\n",
    "start_indices_bad = bad_examples.index[bad_examples['indicator'] == 1].tolist()\n",
    "\n",
    "# Add the end of the DataFrame as the last index\n",
    "start_indices_bad.append(len(bad_examples))\n",
    "\n",
    "# Loop through each segment and plot, limiting the number of rotations\n",
    "for i in range(len(start_indices_bad)-1):\n",
    "    segment = bad_examples.iloc[start_indices_bad[i]:start_indices_bad[i + 1]]\n",
    "    all_bad_segments.append(segment)\n",
    "\n",
    "print(\"Total Bad Cutting Data:\", len(all_bad_segments))\n",
    "print(\"Shape of Segment 1:\", all_bad_segments[0].shape)\n",
    "print(\"Shape of Torque Data:\", all_bad_segments[0]['Torque'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Time-Series into Spectogram Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STFT Spectogram Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 4)\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import spectrogram\n",
    "import random\n",
    "\n",
    "good_stft_features = []\n",
    "bad_stft_features = []\n",
    "\n",
    "def compute_stft_spectrogram(data, fs=500.0, nperseg=512, noverlap=128, nfft=512, cmap='magma'):\n",
    "    f, t, Sxx = spectrogram(data, fs=fs, nperseg=nperseg, noverlap=noverlap, nfft=nfft)\n",
    "    return Sxx\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.pcolormesh(t, f, 10 * np.log10(Sxx), shading='gouraud', cmap=cmap)\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.colorbar(label='Intensity [dB]')\n",
    "    plt.title('STFT Spectrogram for Good Cutting')\n",
    "    plt.show()\n",
    "    fig.savefig(f'/home/admin-anedunga/Desktop/InDas_Template/figures and graphs/good_cutting_stft{random.randint(1, 9)}.png', dpi=fig.dpi)\n",
    "    return Sxx\n",
    "\n",
    "# Plot the spectrogram of the first segment\n",
    "# Sample number\n",
    "MAX_SAMPLES_GOOD = 4540\n",
    "# Sample number\n",
    "MAX_SAMPLES_BAD = 1936\n",
    "\n",
    "#MAX_SAMPLES_GOOD = 3\n",
    "#MAX_SAMPLES_BAD = 3\n",
    "\n",
    "for i in range(MAX_SAMPLES_GOOD):\n",
    "    good_cutting_stft = np.asarray(all_good_segments[i]['Torque'])\n",
    "    good_stft = compute_stft_spectrogram(good_cutting_stft)\n",
    "    good_stft_features.append(good_stft)\n",
    "\n",
    "print(good_stft.shape)\n",
    "   \n",
    "for i in range(MAX_SAMPLES_BAD):\n",
    "    bad_cutting_stft = np.asarray(all_bad_segments[i]['Torque'])\n",
    "    bad_stft = compute_stft_spectrogram(bad_cutting_stft)\n",
    "    bad_stft_features.append(bad_stft)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersample Classes to Balance Them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STFT Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STFT Features Val Shape: (2876, 257, 4)\n",
      "Balanced_Good (1800, 257, 4)\n",
      "Balanced_Bad (1800, 257, 4)\n"
     ]
    }
   ],
   "source": [
    "SAMPLES_FOR_TRAINING = 1800\n",
    "balanced_good_stft_features = np.array(good_stft_features[:SAMPLES_FOR_TRAINING])\n",
    "balanced_bad_stft_features = np.array(bad_stft_features[:SAMPLES_FOR_TRAINING])\n",
    "\n",
    "validation_good_stft_features = np.array(good_stft_features[SAMPLES_FOR_TRAINING:MAX_SAMPLES_GOOD])\n",
    "validation_bad_stft_features = np.array(bad_stft_features[SAMPLES_FOR_TRAINING:MAX_SAMPLES_BAD])\n",
    "\n",
    "validation_good_stft_labels = np.ones(validation_good_stft_features.shape[0])\n",
    "validation_bad_stft_labels = np.zeros(validation_bad_stft_features.shape[0])\n",
    "\n",
    "validation_stft_features = np.concatenate((validation_good_stft_features, validation_bad_stft_features), axis=0)\n",
    "validation_stft_labels = np.concatenate((validation_good_stft_labels, validation_bad_stft_labels), axis=0)\n",
    "print(\"STFT Features Val Shape:\", validation_stft_features.shape)\n",
    "print(\"Balanced_Good\", balanced_good_stft_features.shape)\n",
    "print(\"Balanced_Bad\", balanced_bad_stft_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# Create labels for the features\n",
    "good_labels = [1] * len(balanced_good_stft_features)  # Label 1 for good torque\n",
    "bad_labels = [0] * len(balanced_bad_stft_features)    # Label 0 for bad torque\n",
    "\n",
    "# Combine features and labels\n",
    "features = np.array(balanced_good_stft_features + balanced_bad_stft_features)\n",
    "labels = np.array(good_labels + bad_labels)\n",
    "\n",
    "# Custom Dataset class\n",
    "class MelSpectrogramDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.features[idx]\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(feature, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "dataset = MelSpectrogramDataset(features, labels)\n",
    "train_size = int(0.4 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "val_dataset = MelSpectrogramDataset(validation_stft_features, validation_stft_labels)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin-anedunga/anaconda3/envs/Indas2/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/admin-anedunga/anaconda3/envs/Indas2/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.7094\n",
      "Epoch 2/10, Loss: 0.2365\n",
      "Epoch 3/10, Loss: 0.1165\n",
      "Epoch 4/10, Loss: 0.0743\n",
      "Epoch 5/10, Loss: 0.0527\n",
      "Epoch 6/10, Loss: 0.0392\n",
      "Epoch 7/10, Loss: 0.0328\n",
      "Epoch 8/10, Loss: 0.0277\n",
      "Epoch 9/10, Loss: 0.0241\n",
      "Epoch 10/10, Loss: 0.0212\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# Modify ResNet-18\n",
    "class ResNet18MelSpectrogram(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ResNet18MelSpectrogram, self).__init__()\n",
    "        self.resnet = resnet18(pretrained=False)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),  # Dropout layer before the fully connected layer\n",
    "            nn.Linear(self.resnet.fc.in_features, 2)  # 2 classes: good and bad\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate model, loss function, and optimizer\n",
    "model = ResNet18MelSpectrogram(num_classes=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001, weight_decay=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.unsqueeze(1).to(device), labels.to(device)  # Add channel dimension\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / train_size\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.unsqueeze(1).to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8990/2109216383.py:24: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  return torch.tensor(feature, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Preditions/Total 2740 / 2876\n",
      "Validation Accuracy: 95.27%\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.unsqueeze(1).to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(\"Correct Preditions/Total\", correct, \"/\", total)\n",
    "print(f'Validation Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Validation Scores & Save Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if accuracy > 90:\n",
    "#     torch.save(model.state_dict(),f'model_ResNet18_{accuracy:.2f}.pth')\n",
    "#     print(\"Model Saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Indas2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
